{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Parkinson's Disease detection with saved trained models as an ensemble."
      ],
      "metadata": {
        "id": "OsBRPbgNMfCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import the dependencies."
      ],
      "metadata": {
        "id": "KdgPrRpbHKtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Tuple\n",
        "import random\n",
        "import math\n",
        "import librosa\n",
        "import os\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "SPH37iHZHPnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load the audios with Librosa, and preprocess them using Peak Amplitude Normalization.\n",
        "- load_audio will return all the audios with their sampling rate.\n",
        "- to_positive will turn all values to postive numbers (audio is 1D).\n",
        "- get_max will return the maximum value in each audio array.\n",
        "- peak_amplitude_normalize will preprocess audios with this formula 10 ** (peak / 20) / maximum_value.\n",
        "- hamming_window uses this formula 0.54 - 0.46 * math.cos((2 * math.pi * n) / frame_length - 1) to every frame of the audio and returns windowed audios.\n",
        "- frame_audio_signal uses hamming_window on frames of audios and returns framed audios."
      ],
      "metadata": {
        "id": "EtNZMHEBHeCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio(file_path: str) -> Tuple:\n",
        "    audio, sampling_rate = librosa.load(file_path, sr=44100)\n",
        "    return audio, sampling_rate\n",
        "\n",
        "def to_positive(n_array):  # Turn all values to positive values\n",
        "    for i in range(len(n_array)):\n",
        "        if n_array[i] < 0:\n",
        "            n_array[i] = -1 * n_array[i]\n",
        "    return n_array\n",
        "\n",
        "def get_max(n_array):  # Get the maximum value\n",
        "    max_value = n_array[0]\n",
        "    for i in range(1, len(n_array), 1):\n",
        "        if n_array[i] > max_value:\n",
        "            max_value = n_array[i]\n",
        "    return max_value\n",
        "\n",
        "def peak_amplitude_normalize(audio_data, peak=-3.0):  # Calculate a scaling factor based on the specific peak value\n",
        "    n_array = to_positive(audio_data)               # (-3 dB) and multiply the entire audio signal by the scaling factor\n",
        "    maximum_value = get_max(n_array)\n",
        "    scaling = 10 ** (peak / 20) / maximum_value\n",
        "    normalized_audio = audio_data * scaling\n",
        "    return normalized_audio\n",
        "\n",
        "def hamming_window(frame_length):\n",
        "    window = np.zeros(frame_length)\n",
        "    n_negative_one = frame_length - 1\n",
        "    for n in range(frame_length):\n",
        "        window[n] = 0.54 - 0.46 * math.cos((2 * math.pi * n) / n_negative_one)\n",
        "    return window\n",
        "\n",
        "# Function to frame the signal using a Hamming window\n",
        "def frame_audio_signal(audio_data, frame_length):\n",
        "    length_audio = len(audio_data)\n",
        "    number_frames = length_audio // frame_length\n",
        "    framed_audio = np.zeros((frame_length, number_frames))\n",
        "    for i in range(number_frames):\n",
        "        start = i * frame_length\n",
        "        stop = start + frame_length\n",
        "        samples = audio_data[start:stop] * hamming_window(frame_length)\n",
        "        framed_audio[:, i] = samples\n",
        "    return framed_audio"
      ],
      "metadata": {
        "id": "8LlY7ar7HnLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Extract audio features for saved models.\n",
        "- audio_features_status extracts zero cross rating, energy, MFCC, spectral centroid and spectral rolloff for Logistic Regression, KNN, SVM, Decision Tree, and Random Forest respectively."
      ],
      "metadata": {
        "id": "1GFY4-xNHuhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_features_status() -> Tuple:\n",
        "    directory = '/content/drive/MyDrive/HYP TEST DATA/'\n",
        "    zcr_features = []\n",
        "    energy_features = []\n",
        "    mfcc_features = []\n",
        "    spectral_features = []\n",
        "    audios = []\n",
        "    status = []\n",
        "    for file_name in os.listdir(directory):\n",
        "        if file_name.endswith('.wav'):\n",
        "            if \"P\" in file_name:\n",
        "                status.append(1)\n",
        "            if \"C\" in file_name:\n",
        "                status.append(0)\n",
        "\n",
        "            file_path = os.path.join(directory, file_name)\n",
        "            audio, sampling_rate = load_audio(file_path)\n",
        "            frame_time = 0.02  # Duration of each frame in seconds\n",
        "            frame_size = int(frame_time * sampling_rate)  # Number of samples in each frame\n",
        "            frame_length = int(5 * sampling_rate)\n",
        "            preprocessed_audio = peak_amplitude_normalize(audio)\n",
        "            frames = frame_audio_signal(preprocessed_audio, frame_size)\n",
        "\n",
        "            zcr = np.mean(np.abs(np.diff(np.sign(frames))), axis=1)\n",
        "            zcr_features.append(zcr.mean())\n",
        "\n",
        "            framed_audio = frame_audio_signal(preprocessed_audio, frame_length)\n",
        "            energy = np.sum(framed_audio ** 2, axis=0)\n",
        "            energy_features.append(energy)\n",
        "\n",
        "            mfcc = np.mean(librosa.feature.mfcc(y=preprocessed_audio, sr=sampling_rate, n_mfcc=13).T, axis=0)\n",
        "            mfcc_features.append(mfcc)\n",
        "\n",
        "            spectral_centroid = librosa.feature.spectral_centroid(y=preprocessed_audio, sr=sampling_rate).mean()\n",
        "            spectral_roll_off = librosa.feature.spectral_rolloff(y=preprocessed_audio, sr=sampling_rate).mean()\n",
        "            feats = np.array([spectral_centroid, spectral_roll_off])\n",
        "            spectral_features.append(feats)\n",
        "\n",
        "            audios.append(np.expand_dims(preprocessed_audio, axis=0))\n",
        "\n",
        "    zcr_features, energy_features, mfcc_features, spectral_features, audios, status = np.array(zcr_features), np.array(energy_features), np.array(mfcc_features), np.array(spectral_features), np.array(audios), np.array(status)\n",
        "    return zcr_features, energy_features, mfcc_features, spectral_features, audios, status"
      ],
      "metadata": {
        "id": "EA7BF58lIuaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### voting below takes majority voting of the predictions made by each of the loaded model."
      ],
      "metadata": {
        "id": "0yh02EgTI17H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def voting(predicted_values):\n",
        "     positive, negative = 0, 0\n",
        "     for i in range(len(predicted_values)):\n",
        "         if predicted_values[i] == 1:\n",
        "             positive += 1\n",
        "         else:\n",
        "              negative += 1\n",
        "     if positive >= negative:\n",
        "         return 1\n",
        "     else:\n",
        "          return 0"
      ],
      "metadata": {
        "id": "uvnAvyiPJKdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Metrics\n",
        "- _confusion_matrix computes true positives, fales positives, true negatives, and false negatives.\n",
        "- accuracy_score, precision_score, recall_score, f1_score andd confusion_matrix compute accuracy, precison, recall, and f1 scores and confusion matrix."
      ],
      "metadata": {
        "id": "Ygcup-zvJWrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _confusion_matrix(y_testing, y_prediction):\n",
        "    # Computing confusion matrix\n",
        "    length_of_labels = len(y_testing)\n",
        "    true_positive, false_positive, true_negative, false_negative = 0, 0, 0, 0\n",
        "\n",
        "    for i in range(length_of_labels):\n",
        "        if y_testing[i] == 1:\n",
        "            if y_testing[i] == y_prediction[i]:\n",
        "                true_positive += 1\n",
        "\n",
        "            else:\n",
        "                false_positive += 1\n",
        "\n",
        "        if y_testing[i] == 0:\n",
        "            if y_testing[i] == y_prediction[i]:\n",
        "                true_negative += 1\n",
        "\n",
        "            else:\n",
        "                false_negative += 1\n",
        "\n",
        "    return true_positive, false_positive, true_negative, false_negative\n",
        "\n",
        "\n",
        "def accuracy_score(y_testing, y_preds):\n",
        "    tp, fp, tn, fn = _confusion_matrix(y_testing, y_preds)\n",
        "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def precision_score(y_testing, y_preds):\n",
        "    tp, fp, tn, fn = _confusion_matrix(y_testing, y_preds)\n",
        "    precision = tp / (tp + fp)\n",
        "    return precision\n",
        "\n",
        "\n",
        "def recall_score(y_testing, y_preds):\n",
        "    tp, fp, tn, fn = _confusion_matrix(y_testing, y_preds)\n",
        "    tp_fn = tp + fn\n",
        "    if tp_fn == 0:\n",
        "        return 0.0\n",
        "    else:\n",
        "        recall = tp / tp_fn\n",
        "        return recall\n",
        "\n",
        "\n",
        "def f1_score(y_testing, y_preds):\n",
        "    precision = precision_score(y_testing, y_preds)\n",
        "    recall = recall_score(y_testing, y_preds)\n",
        "    precision_recall = precision + recall\n",
        "    if precision_recall == 0:\n",
        "        return 0.0\n",
        "    else:\n",
        "        f1 = (2 * precision * recall) / precision_recall\n",
        "        return f1\n",
        "\n",
        "\n",
        "def confusion_matrix(y_testing, y_preds):\n",
        "    tp, fp, tn, fn = _confusion_matrix(y_testing, y_preds)\n",
        "    con_mat = []\n",
        "    positives = [tp, fp]\n",
        "    negatives = [fn, tn]\n",
        "    con_mat.append(positives)\n",
        "    con_mat.append(negatives)\n",
        "    return con_mat"
      ],
      "metadata": {
        "id": "yfYv6aOkJm1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Main function."
      ],
      "metadata": {
        "id": "psxl_jVZJy6d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DOm7nJihcDo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "0e2fc1ca-6db1-4c90-c4eb-fe2e924c8d99"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/utils/path.py\u001b[0m in \u001b[0;36mget_py_filename\u001b[0;34m(name, force_win32)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File `%r` not found.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: File `'DecisionTree.py'` not found.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-83d2aaee9356>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\"DecisionTree\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-52>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^'.*'$\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'For Windows, use double quotes to wrap a filename: %run \"mypath\\\\myfile.py\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: File `'DecisionTree.py'` not found."
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "   zcr, energy, mfcc, spectrals, audios, status = audio_features_status()\n",
        "   logistic_reg = \"logistic_reg_model.pkl\"\n",
        "   knn = \"knn_model.pkl\"\n",
        "   svm = \"svm_model.pkl\"\n",
        "   decision_tree= \"tree_model.pkl\"\n",
        "   random_forest = \"random_model.pkl\"\n",
        "   one_dcnn_model = load_model(\"1dcnn.h5\")\n",
        "\n",
        "   with open(logistic_reg, 'rb') as file:\n",
        "        logistic_reg_model = pickle.load(file)\n",
        "\n",
        "   with open(knn, 'rb') as file:\n",
        "        knn_model = pickle.load(file)\n",
        "\n",
        "   with open(svm, 'rb') as file:\n",
        "        svm_model = pickle.load(file)\n",
        "\n",
        "   with open(decision_tree, 'rb') as file:\n",
        "        tree_model = pickle.load(file)\n",
        "\n",
        "   with open(random_forest, 'rb') as file:\n",
        "        random_model = pickle.load(file)\n",
        "\n",
        "   logistic_reg_model_preds = logistic_reg_model.predict(zcr)\n",
        "   knn_model_preds = knn_model.predict(energy)\n",
        "   svm_model_preds = svm_model.estimate(mfcc)\n",
        "   tree_model_preds = tree_model.preict(spectrals)\n",
        "   random_model_preds = random_model.predict(spectrals)\n",
        "\n",
        "   one_dcnn_model_preds = []\n",
        "   threshold = 0.5\n",
        "   for audio in audios:\n",
        "        pred = one_dcnn_model.predict(audio)\n",
        "        if pred >= threshold:\n",
        "            one_dcnn_model_preds.append(1)\n",
        "        else:\n",
        "             one_dcnn_model_preds.append(0)\n",
        "\n",
        "   ensemble_preds = []\n",
        "   for i in range(len(logistic_reg_model_preds)):\n",
        "        temp_preds = []\n",
        "        temp_preds.append(logistic_reg_model_preds[i])\n",
        "        temp_preds.append(knn_model_preds[i])\n",
        "        temp_preds.append(svm_model_preds[i])\n",
        "        temp_preds.append(tree_model_preds[i])\n",
        "        temp_preds.append(random_model_preds[i])\n",
        "        temp_preds.append(one_dcnn_model_preds[i])\n",
        "        ensemble_preds.append(voting(temp_preds))\n",
        "\n",
        "   ensemble_accuracy = accuracy_score(status, ensemble_preds)\n",
        "   ensemble_precision = precision_score(status, ensemble_preds)\n",
        "   ensemble_recall = recall_score(status, ensemble)\n",
        "   ensemble_f1 = f1_score(status, ensemble_preds)\n",
        "   ensemble_confusion_mat = confusion_matrix(status, ensemble_preds)\n",
        "\n",
        "   print(\"Ensemble accuracy on the testing data:\", ensemble_accuracy)\n",
        "   print(\"Ensemble precision on the testing data:\", ensemble_precision)\n",
        "   print(\"Ensemble recall on the testing data:\", ensemble_recall)\n",
        "   print(\"Ensemble F1 score on the testing fata:\", ensemble_f1)\n",
        "   print(\"Ensemble confusion matrix on the testing data:\", ensemble_confusion_mat)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOxqfPyZAolm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}